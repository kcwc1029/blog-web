<!DOCTYPE html>
<html>
	<head>
		<meta charset="UTF-8" />
		<title>PoseNet_Single</title>
		<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
		<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/posenet"></script>
	</head>
	<body>
		<video autoplay muted id="video" width="400" height="400"></video>
		<canvas id="output" style="position: absolute; top: 0; left: 0"></canvas>
	</body>
	<script>
		const color = "aqua"; // 定義繪製關鍵點和骨架的顏色
		const boundingBoxColor = "red"; // 定義邊界框的顏色
		const lineWidth = 2; // 定義線條寬度

		// 將物件轉換為座標陣列
		function toTuple({ y, x }) {
			return [y, x];
		}

		// 繪製關鍵點
		function drawPoint(ctx, y, x, r, color) {
			ctx.beginPath(); // 開始繪製路徑
			ctx.arc(x, y, r, 0, 2 * Math.PI); // 繪製圓形
			ctx.fillStyle = color; // 設置填充顏色
			ctx.fill(); // 填充圓形
		}

		// 繪製所有關鍵點
		function drawKeypoints(keypoints, minConfidence, ctx, scale = 1) {
			for (let i = 0; i < keypoints.length; i++) {
				const keypoint = keypoints[i];
				// 如果關鍵點的置信度低於最小值，則跳過
				if (keypoint.score < minConfidence) {
					continue;
				}
				const { y, x } = keypoint.position; // 獲取關鍵點的座標
				drawPoint(ctx, y * scale, x * scale, 3, color); // 繪製關鍵點
			}
		}

		// 繪製骨架的線段
		function drawSegment([ay, ax], [by, bx], color, scale, ctx) {
			ctx.beginPath(); // 開始繪製路徑
			ctx.moveTo(ax * scale, ay * scale); // 移動到起點
			ctx.lineTo(bx * scale, by * scale); // 繪製線段到終點
			ctx.lineWidth = lineWidth; // 設置線條寬度
			ctx.strokeStyle = color; // 設置線條顏色
			ctx.stroke(); // 繪製線段
		}

		// 繪製骨架
		function drawSkeleton(keypoints, minConfidence, ctx, scale = 1) {
			// 獲取相鄰的關鍵點
			const adjacentKeyPoints = posenet.getAdjacentKeyPoints(keypoints, minConfidence);
			// 遍歷每個相鄰的關鍵點對
			adjacentKeyPoints.forEach((keypoints) => {
				drawSegment(toTuple(keypoints[0].position), toTuple(keypoints[1].position), color, scale, ctx); // 繪製線段
			});
		}

		// 設置網路攝影機
		async function setupWebcam() {
			video = document.getElementById("video"); // 獲取 video 元素
			// 請求使用者授權使用攝影機
			const stream = await navigator.mediaDevices.getUserMedia({
				audio: false, // 不啟用音訊
				video: { facingMode: "user" }, // 使用前置鏡頭
			});
			video.srcObject = stream; // 將攝影機串流綁定到 video 元素
			// 返回一個 Promise，當 video 的 metadata 加載完成時解析
			return new Promise((resolve) => {
				video.onloadedmetadata = () => {
					resolve(video); // 解析 video 元素
				};
			});
		}

		// 檢測姿勢
		async function detect() {
			let minPoseConfidence = 0.1; // 姿勢的最小置信度
			let minPartConfidence = 0.5; // 關鍵點的最小置信度
			// 使用 PoseNet 模型預測單一姿勢
			const pose = await model.estimateSinglePose(video, {
				flipHorizontal: false, // 不水平翻轉
			});
			console.log(pose); // 在控制台輸出姿勢資訊
			ctx.clearRect(0, 0, canvas.width, canvas.height); // 清除畫布
			// 如果姿勢的置信度大於等於最小值
			if (pose.score >= minPoseConfidence) {
				drawKeypoints(pose.keypoints, minPartConfidence, ctx); // 繪製關鍵點
				drawSkeleton(pose.keypoints, minPartConfidence, ctx); // 繪製骨架
			}
			requestAnimationFrame(detect); // 使用 requestAnimationFrame 持續進行檢測
		}

		// 主函數
		async function app() {
			await setupWebcam(); // 設置並啟動攝影機
			video.play(); // 播放 video 元素
			// 獲取 video 的實際寬度和高度
			videoWidth = video.videoWidth;
			videoHeight = video.videoHeight;
			video.width = videoWidth; // 設置 video 元素的寬度
			video.height = videoHeight; // 設置 video 元素的高度
			// 獲取畫布元素並設置其寬度和高度
			canvas = document.getElementById("output");
			canvas.width = videoWidth;
			canvas.height = videoHeight;
			// 獲取畫布的 2D 繪圖上下文
			ctx = canvas.getContext("2d");
			// 加載 PoseNet 模型
			model = await posenet.load({
				architecture: "MobileNetV1", // 使用 MobileNetV1 架構
				outputStride: 16, // 設置輸出步幅
				multiplier: 0.75, // 設置乘數
			});
			detect();
		}
		app();
	</script>
</html>
