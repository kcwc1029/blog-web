<!DOCTYPE html>
<html>
	<head>
		<meta charset="utf-8" />
		<title>MINIST02</title>
		<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"></script>
		<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-vis@latest"></script>
		<script src="data.js"></script>
	</head>
	<body>
		<script>
			// TODO: 創建一個卷積神經網路模型
			function createModel() {
				const model = tf.sequential(); // 創建一個順序模型
				// 添加第一個卷積層
				model.add(
					tf.layers.conv2d({
						inputShape: [28, 28, 1], // 輸入形狀為 28x28x1（MNIST 圖像的標準形狀）
						kernelSize: 5, // 卷積核大小為 5x5
						filters: 8, // 使用 8 個過濾器
						strides: 1, // 步幅為 1
						activation: "relu", // 使用 ReLU 激活函數
						kernelInitializer: "varianceScaling", // 使用方差縮放初始化權重
					})
				);
				// 添加第一個最大池化層
				model.add(
					tf.layers.maxPooling2d({
						poolSize: [2, 2], // 池化窗口大小為 2x2
						strides: [2, 2], // 步幅為 2
					})
				);
				// 添加第二個卷積層
				model.add(
					tf.layers.conv2d({
						kernelSize: 5, // 卷積核大小為 5x5
						filters: 16, // 使用 16 個過濾器
						strides: 1, // 步幅為 1
						activation: "relu", // 使用 ReLU 激活函數
						kernelInitializer: "varianceScaling", // 使用方差縮放初始化權重
					})
				);
				// 添加第二個最大池化層
				model.add(
					tf.layers.maxPooling2d({
						poolSize: [2, 2], // 池化窗口大小為 2x2
						strides: [2, 2], // 步幅為 2
					})
				);
				model.add(tf.layers.flatten()); // 將多維張量展平為一維
				// 添加全連接層（輸出層）
				model.add(
					tf.layers.dense({
						units: 10, // 輸出 10 個類別（MNIST 有 10 個數字）
						activation: "softmax", // 使用 softmax 激活函數進行多分類
						kernelInitializer: "varianceScaling", // 使用方差縮放初始化權重
					})
				);
				// 編譯模型
				model.compile({
					loss: "categoricalCrossentropy", // 使用分類交叉熵作為損失函數
					optimizer: "adam", // 使用 Adam 優化器
					metrics: ["accuracy"], // 使用準確率作為評估指標
				});
				// 顯示模型摘要
				tfvis.show.modelSummary({ name: "Model Summary" }, model);
				return model;
			}

			// TODO: 獲取 MNIST 數據
			async function getData() {
				data = new MnistData(); // 創建 MnistData 實例
				await data.load(); // 加載數據
				return data;
			}

			// TODO: 獲取訓練數據
			function getTrainData(data, size) {
				return tf.tidy(() => {
					// 使用 tf.tidy 自動清理中間張量
					const d = data.nextTrainBatch(size); // 獲取下一批訓練數據
					return {
						inputs: d.xs.reshape([size, 28, 28, 1]), // 將輸入數據重塑為 28x28x1 的形狀
						labels: d.labels, // 獲取標籤
					};
				});
			}

			// TODO: 獲取測試數據
			function getTestData(data, size) {
				return tf.tidy(() => {
					// 使用 tf.tidy 自動清理中間張量
					const d = data.nextTestBatch(size); // 獲取下一批測試數據
					return {
						inputs: d.xs.reshape([size, 28, 28, 1]), // 將輸入數據重塑為 28x28x1 的形狀
						labels: d.labels, // 獲取標籤
					};
				});
			}

			// TODO: 訓練模型
			async function trainModel(model, t_data, v_data) {
				const batchSize = 500; // 設置批次大小
				const epochs = 10; // 設置訓練週期
				return await model.fit(t_data.inputs, t_data.labels, {
					batchSize,
					epochs,
					shuffle: true, // 設置批次大小、訓練週期和是否打亂數據
					validationData: [v_data.inputs, v_data.labels], // 設置驗證數據
					callbacks: tfvis.show.fitCallbacks(
						// 添加回調函數以可視化訓練過程
						{ name: "Training Performance" },
						["loss", "val_loss", "acc", "val_acc"], // 顯示損失和準確率
						{ yLabel: "loss/acc", height: 200, callbacks: ["onEpochEnd"] }
					),
				});
			}

			// 定義類別名稱（MNIST 的數字 0-9）
			const classNames = ["0", "1", "2", "3", "4", "5", "6", "7", "8", "9"];

			// TODO: 使用模型進行預測並評估準確率
			async function predictModel(model, data, size = 500) {
				// 獲取測試數據
				const t_data = data.nextTestBatch(size);
				const t_xs = t_data.xs.reshape([size, 28, 28, 1]); // 重塑輸入數據
				const labels = t_data.labels.argMax(-1); // 獲取真實標籤
				const preds = model.predict(t_xs).argMax(-1); // 進行預測並獲取預測結果
				t_xs.dispose(); // 釋放輸入數據的記憶體
				// 計算每個類別的準確率
				const classAccuracy = await tfvis.metrics.perClassAccuracy(labels, preds);
				// 設置可視化容器
				const container = { name: "Accuracy", tab: "Evaluation" };
				// 顯示每個類別的準確率
				tfvis.show.perClassAccuracy(container, classAccuracy, classNames);
				labels.dispose(); // 釋放標籤的記憶體
			}

			// 主函數，執行整個流程
			async function run() {
				const model = createModel(); // 創建模型
				const data = await getData(); // 獲取數據
				const t_data = getTrainData(data, 5500); // 獲取訓練數據
				const v_data = getTestData(data, 1000); // 獲取驗證數據
				await trainModel(model, t_data, v_data); // 訓練模型
				predictModel(model, data); // 進行預測並評估模型
			}

			// 執行主函數
			run();
		</script>
	</body>
</html>
