<!DOCTYPE html>
<html>
	<head>
		<meta charset="UTF-8" />
		<title>webCam+Blazeface</title>
		<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"></script>
		<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface"></script>
	</head>
	<body>
		<video id="video" style="-webkit-transform: scaleX(-1); transform: scaleX(-1); width: auto; height: auto"></video>
		<canvas id="output" style="position: absolute; top: 0; left: 0"></canvas>
		<div id="result">...</div>
	</body>
	<script>
		// 設置網路攝影機
		async function setupWebcam() {
			video = document.getElementById("video"); // 獲取 video 元素
			// 請求使用者授權使用攝影機
			const stream = await navigator.mediaDevices.getUserMedia({
				audio: false, // 不啟用音訊
				video: { facingMode: "user" }, // 使用前置鏡頭
			});
			video.srcObject = stream; // 將攝影機串流綁定到 video 元素

			// 返回一個 Promise，當 video 的 metadata 加載完成時解析
			return new Promise((resolve) => {
				video.onloadedmetadata = () => {
					resolve(video); // 解析 video 元素
				};
			});
		}

		// 預測人臉
		async function predict() {
			// 使用 BlazeFace 模型預測 video 中的人臉
			const predictions = await model.estimateFaces(video, false, true, true);
			document.getElementById("result").innerHTML = ""; // 清空結果顯示區域
			// 如果有檢測到人臉
			if (predictions.length > 0) {
				ctx.clearRect(0, 0, canvas.width, canvas.height); // 清除畫布
				// 遍歷每個檢測到的人臉
				for (let i = 0; i < predictions.length; i++) {
					try {
						// 在結果顯示區域中顯示人臉的置信度
						document.getElementById("result").innerHTML += "Probability " + i + " : " + predictions[i].probability + "<br>";
						console.log(predictions[i]); // 在控制台輸出預測結果
					} catch (err) {
						// 如果發生錯誤，顯示錯誤訊息
						document.getElementById("result").innerHTML = err.message;
					}
					const start = predictions[i].topLeft; // 人臉的左上角座標
					const end = predictions[i].bottomRight; // 人臉的右下角座標
					const size = [end[0] - start[0], end[1] - start[1]]; // 計算人臉的寬度和高度
					// 設置填充顏色為半透明的紅色
					ctx.fillStyle = "rgba(255, 0, 0, 0.2)";
					// 在畫布上繪製人臉的矩形區域
					ctx.fillRect(start[0], start[1], size[0], size[1]);
					// 獲取人臉的特徵點（landmarks）
					const landmarks = predictions[i].landmarks;
					// 設置填充顏色為藍色
					ctx.fillStyle = "blue";
					// 遍歷每個特徵點
					for (let j = 0; j < landmarks.length; j++) {
						const x = landmarks[j][0]; // 特徵點的 x 座標
						const y = landmarks[j][1]; // 特徵點的 y 座標
						// 在畫布上繪製特徵點（小矩形）
						ctx.fillRect(x, y, 5, 5);
					}
				}
			} else {
				// 如果沒有檢測到人臉，清除畫布
				ctx.clearRect(0, 0, canvas.width, canvas.height);
			}
			// 使用 requestAnimationFrame 持續進行預測
			requestAnimationFrame(predict);
		}

		// 主函數
		async function app() {
			await setupWebcam(); // 設置並啟動攝影機
			video.play(); // 播放 video 元素
			// 獲取 video 的實際寬度和高度
			videoWidth = video.videoWidth;
			videoHeight = video.videoHeight;
			video.width = videoWidth; // 設置 video 元素的寬度
			video.height = videoHeight; // 設置 video 元素的高度
			// 獲取畫布元素並設置其寬度和高度
			canvas = document.getElementById("output");
			canvas.width = videoWidth;
			canvas.height = videoHeight;
			// 獲取畫布的 2D 繪圖上下文
			ctx = canvas.getContext("2d");
			ctx.fillStyle = "rgba(255, 0, 0, 0.5)"; // 設置填充顏色為半透明的紅色
			// 加載 BlazeFace 模型
			model = await blazeface.load();
			predict();
		}
		app();
	</script>
</html>
