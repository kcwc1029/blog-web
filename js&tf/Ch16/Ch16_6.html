<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Ch16_6.html</title>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/posenet"></script>
</head>
<body>
<video autoplay muted id="video" width="400" height="400"></video>
<canvas id="output" style="position:absolute;top:0;left:0;"></canvas>
<script>
const color = "aqua";  
const boundingBoxColor = "red";
const lineWidth = 2;

function toTuple({y, x}) {
  return [y, x];
}

function drawPoint(ctx, y, x, r, color) {
  ctx.beginPath();
  ctx.arc(x, y, r, 0, 2 * Math.PI);
  ctx.fillStyle = color;
  ctx.fill();
}   
    
function drawKeypoints(keypoints, minConfidence, ctx, scale=1) {
  for (let i = 0; i < keypoints.length; i++) {
    const keypoint = keypoints[i];
    if (keypoint.score < minConfidence) {
      continue;
    }
    const {y, x} = keypoint.position;
    drawPoint(ctx, y * scale, x * scale, 3, color);
  }
}
   
function drawSegment([ay, ax], [by, bx], color, scale, ctx) {
  ctx.beginPath();
  ctx.moveTo(ax * scale, ay * scale);
  ctx.lineTo(bx * scale, by * scale);
  ctx.lineWidth = lineWidth;
  ctx.strokeStyle = color;
  ctx.stroke();
}

function drawSkeleton(keypoints, minConfidence, ctx, scale=1) {
  const adjacentKeyPoints =
    posenet.getAdjacentKeyPoints(keypoints, minConfidence);

  adjacentKeyPoints.forEach((keypoints) => {
    drawSegment(
      toTuple(keypoints[0].position), toTuple(keypoints[1].position), color,
      scale, ctx);
  });
} 

async function setupWebcam() {
  video = document.getElementById("video");
  const stream = await navigator.mediaDevices.getUserMedia({
    "audio": false,
    "video": { facingMode: "user" },
  });
  video.srcObject = stream;
    
  return new Promise((resolve) => {
    video.onloadedmetadata = () => {
      resolve(video);
    };
  });
}
    
async function detect() {
  let minPoseConfidence = 0.1;
  let minPartConfidence = 0.5;
  const pose = await model.estimateSinglePose(video, {
    flipHorizontal: false
  });
  console.log(pose);
  ctx.clearRect(0, 0, canvas.width, canvas.height);
  if (pose.score >= minPoseConfidence) {
    drawKeypoints(pose.keypoints, minPartConfidence, ctx);
    drawSkeleton(pose.keypoints, minPartConfidence, ctx);
  }
  requestAnimationFrame(detect);
}

async function app() {
  await setupWebcam(); 
  video.play();
  videoWidth = video.videoWidth;
  videoHeight = video.videoHeight;
  video.width = videoWidth;
  video.height = videoHeight;
    
  canvas = document.getElementById("output");
  canvas.width = videoWidth;
  canvas.height = videoHeight;
  ctx = canvas.getContext('2d');
    
  model = await posenet.load({
    architecture: 'MobileNetV1',
    outputStride: 16,
    multiplier: 0.75
  });
  detect();
}
app();
</script>
</body>
</html>